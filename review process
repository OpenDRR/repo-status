Objective: Develop and summarize the review process for different types of datasets published by the NRCan risk team, and which could be released to the public domain.

Resources:
•	Roadmap for Open Science: https://www.ic.gc.ca/eic/site/063.nsf/eng/h_97992.html
•	How to implement a decision system? https://canada-ca.github.io/digital-playbook-guide-numerique/views-vues/automated-decision-automatise/en/automated-decision.html\
•	NRCan Scientific Integrity Policy: https://www.nrcan.gc.ca/scientific-integrity/21665

Working Principals:
OpenDRR is an open science project where the input datasets, calculation methods, and outputs are published in GitHub, so can be made public at any time, and can be continually updated. The key questions is: how to manage the state of review given the evolving information? The following principals appear to guide the process:
•	Different types of information require different levels of review depending on their potential impact. 
•	A process of review can be implemented such that it follows the organization review standards, justifies when information can be made private in an open science process, and facilities collective alignment on review practices.
•	The author of the information (dataset or metadata), provided that they have followed the review process at a minimum, has the authority to decide when information is published and to what review standard.   
•	A system of versioning can be used to indicate in progress, peer review, and finalized datasets.\
 
Types of Information That Require Review:
•	Meta data (e.g. data dictionary, supporting text information within a repository or on a website)
•	Spatial data (e.g. geometry files, surveyed information, interpreted datasets).
•	Non-spatial data 
•	Source code
•	Documentation (e.g. reports, publications)
 
Preliminary Workflow:
1.	Is this protected information? 
2.	(proposed step to remove the burden of effort on users) Is this information obtained directly from a credible source, involves very little interpretation, or is accompanying meta-data?  
a.	The above sentence is not quite right, but it’s some early stop gap measure for datasets that really aren’t a big deal (e.g. basic meta data, hex-bin geometries). In these cases, internal review from one other, as well as QC for datasets is all we need. 
3.	Impact assessment:
a.	Low (e.g. hex bins). Information stored in public report, quality control check and review from one internal team member required before repo is public. 
b.	Medium (e.g. NHSL). Information can potentially be stored on a public repo with access to data, however disclaimer is included (e.g. use at own risk). Publication is at the discretion of the author.
c.	High (PSRA). Information stored in private repo until datasets are finalized and posted on FGP.
